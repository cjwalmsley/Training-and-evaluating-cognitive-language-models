# config.yml

project_name: "Training-and-evaluating-cognitive-language-models"

file_locations:
  base_directory_windows: "G:\\My Drive\\Shared with Julia\\Education\\Kent University\\PhD\\work\\annabell"
  base_directory_linux: "/home/chris/gdrive/work/annabell"
  base_directory_mac: "/Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell"
  prompt_data_directory: "experiments/data/prompts"
  prompt_inputs_jsonl_filename: "prompt_inputs.jsonl"
  base_prompt_filename: "base_prompt.txt"
  responses_data_directory: "experiments/data/responses"
  responses_jsonl_filename: "responses.jsonl"
  docker_data_directory_mac: "/Users/chris/PycharmProjects/Training-and-evaluating-cognitive-language-models/docker"
  docker_data_directory_linux: "/home/chris/PycharmProjects/Training-and-evaluating-cognitive-language-models/docker"
  docker_data_directory_windows: "C:\\PycharmProjects\\Training-and-evaluating-cognitive-language-models\\docker"
  pre_training_directory: "pre_training"
  pre_training_filename: "nyc_squad_pretraining_commands.txt"
  training_directory: "training"
  training_filename: "nyc_squad_training_commands.txt"
  testing_directory: "testing"
  testing_filename: "nyc_squad_testing_commands.txt"
  experiments_directory: "experiments"
  log_archive_directory: "logs"
  prepared_dataset_directory: "data"
  prepared_dataset_filename: "response_formatted_20250924_174653.jsonl"
  pretraining_validation_testing_filename: "nyc_squad_pretraining_validation_testing_commands.txt"
  categorised_questions_filename: "llm_question_categorisation_results.jsonl"
  categorised_statements_filename: "llm_sentence_categorisation_results.jsonl"
  prepared_dataset_with_commands_filename: "nyc_squad_with_pretraining_commands.jsonl"

experiments:
  experiment_name: "15"
  percentage_of_pretraining_samples: 10
  maximum_number_of_words: 50
  maximum_word_length: 25


dataset:
  dataset_directory: "datasets/squad_dataset"

ollama:
  options:
    num_ctx: 4096
    repeat_last_n: 64
    repeat_penalty: 1.5
    temperature: 0
    seed: 42
    num_predict: 100
    top_k: 1
    top_p: 0.1
    min_p: 0.0
  model: "qwen3:4b"
  embedding_model: "embeddinggemma"
  stream: false
  think: false
  models:
    - "llama3.2"
    - "llama3"
    - "deepseek-r1:8b"
    - "gemma3:4b"
    - "gemma3:1b"
    - "gemma3n:e4b"
    - "qwen3:4b"