# config.yml

project_name: "Training-and-evaluating-cognitive-language-models"

file_locations:
  base_directory_windows: "G:\\My Drive\\Shared with Julia\\Education\\Kent University\\PhD\\work\\annabell"
  base_directory_linux: "/home/chris/gdrive/work/annabell"
  base_directory_mac: "/Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell"
  prompt_data_directory: "llm_data/prompts"
  prompt_directory: "prompts"
  prompt_inputs_jsonl_filename: "prompt_inputs.jsonl"
  base_prompt_filename: "base_prompt.txt"
  responses_data_directory: "llm_data/responses"
  responses_jsonl_filename: "responses.jsonl"
  response_declarative_sentence_categories_filename: "responses_declarative_sentence_categories.jsonl"
  response_interrogative_sentence_categories_filename: "responses_interrogative_sentence_categories.jsonl"
  docker_directory_mac: "/Users/chris/PycharmProjects/Training-and-evaluating-cognitive-language-models/docker"
  docker_directory_linux: "/home/chris/PycharmProjects/Training-and-evaluating-cognitive-language-models/docker"
  docker_directory_windows: "C:\\PycharmProjects\\Training-and-evaluating-cognitive-language-models\\docker"
  docker_data_directory: "shared_data"
  docker_runtime_data_directory: "data"
  pre_training_directory: "pre_training"
  pre_training_filename: "nyc_squad_pretraining_commands.txt"
  training_directory: "training"
  training_filename: "nyc_squad_training_commands.txt"
  testing_directory: "testing"
  testing_filename: "nyc_squad_testing_commands.txt"
  results_directory: "results"
  test_answer_summary_filename: "test_answer_summary_tsv"
  test_detailed_results_filename: "test_detailed_results_tsv"
  test_summary_results_filename: "test_summary_results_txt"
  experiments_directory: "experiments"
  log_archive_directory: "logs"
  annabell_log_pre_training_filename: "annabell_pre_training_log.txt"
  annabell_log_pre_training_validation_testing_filename: "annabell_pre_training_validation_testing_log.txt"
  annabell_log_training_filename: "annabell_training_log.txt"
  annabell_log_testing_filename: "annabell_testing_log.txt"
  prepared_dataset_directory: "data_sets"
  prepared_dataset_filename: "prepared_dataframe.jsonl"
  pre_training_validation_testing_filename: "nyc_squad_pretraining_validation_testing_commands.txt"
  categorised_questions_filename: "llm_question_categorisation_results.jsonl"
  categorised_statements_filename: "llm_sentence_categorisation_results.jsonl"
  prepared_dataset_with_commands_filename: "nyc_squad_with_pretraining_commands.jsonl"
  prepared_dataset_pre_commands_filename: "nyc_squad_without_pretraining_commands.jsonl"
  classify_sentence_prompt_part_1_filename: "classify_sentence_prompt_part_1.txt"
  classify_sentence_prompt_part_2_filename: "classify_sentence_prompt_part_2.txt"
  sentence_patterns_filename: "sentence_patterns.jsonl"
  dataset_with_generated_sentences_filename: "squad_dataset_with_generated_sentences.jsonl"
  dataset_with_sentence_categories_filename: "squad_dataset_with_sentence_categories.jsonl"
  test_pre_training_validation_results_dataframe_filename: "squad_dataset_with_pre_training_validation_results.jsonl"
  test_results_dataframe_filename: "squad_dataset_with_testing_results"
  annabell_weights_directory: "annabell/links"

experiments:
  experiment_name: "45"
  percentage_of_pretraining_samples: 75
  maximum_number_of_words: 18
  maximum_word_length: 25
  maximum_phrase_length: 9
  number_of_training_samples: 1500
  use_all_available_samples: false
  cosine_distance_threshold: 0.1
  auto_save_weights: false
  save_weights_every_n_steps: 25
  log_stats: true
  exclude_samples_with_fewer_than_2_lookups: false
  pre_load_weights: false
  pre_load_weights_filename: "links_people.dat"
  join_entity_words: false
  categorise_samples: false
  goal_stack_limit: 1
  write_non_lookup_commands: false

dataset:
  dataset_directory: "datasets/squad_dataset"
  splits:
    training: "train"
    validation: "validation"
  dataset_directory_linux: "/home/chris/datasets/squad_dataset"

nlp:
  spacy_model: "en_core_web_md"

ollama:
  options:
    num_ctx: 2048
    repeat_last_n: 64
    repeat_penalty: 1.5
    temperature: 0
    seed: 42
    num_predict: 75
    top_k: 1
    top_p: 0.0
    min_p: 0.0
  model: "ministral-3:8b"
  embedding_model: "embeddinggemma"
  stream: false
  think: false
  models:
    - "llama3.2"
    - "llama3"
    - "deepseek-r1:8b"
    - "gemma3:4b"
    - "gemma3:1b"
    - "gemma3n:e4b"
    - "qwen3:4b"
    - "gemma3:12b-it-qat"
    - "qwen3-vl:8b"
    - "mistral-nemo:12b"
    - "gemma3:1b-it-qat"
    - "gemma3:4b-it-qat"
    - "gemma3:27b-it-qat"
    - "ministral-3:8b"