{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T07:23:56.125529Z",
     "start_time": "2025-11-19T07:23:48.829186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config.global_config import GlobalConfig\n",
    "from pipeline import Pipeline\n",
    "from training import AnnabellPreTrainingTestingRunner\n",
    "\n",
    "global_config = GlobalConfig()\n",
    "\n",
    "pipeline = Pipeline(prepared_dataset_filepath=global_config.prepared_dataset_with_commands_filepath())\n",
    "pipeline.load_prepared_dataset()\n",
    "pipeline.run_pre_training_evaluation_testing()\n",
    "pipeline.run_evaluate_pre_training_results()\n",
    "#runner = AnnabellPreTrainingTestingRunner(pipeline.dataset_processor)\n",
    "#runner.move_annabell_logfile_to_gdrive()"
   ],
   "id": "16978073ec3a4ba7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-19 07:23:48,832 - root - INFO - Logging initialized. Log file: /Users/chris/logs/cognitive_language_model_logs/run_20251119_072348.log\n",
      "2025-11-19 07:23:50,940 - pipeline - INFO - Loading prepared dataset from /Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell/experiments/sandbox/data_sets/nyc_squad_with_pretraining_commands.jsonl...\n",
      "2025-11-19 07:23:51,725 - pipeline - INFO - Prepared dataset loaded successfully.\n",
      "2025-11-19 07:23:51,726 - pipeline - INFO - Starting pre-training testing...\n",
      "2025-11-19 07:23:51,728 - dataset_processing - INFO - file written: /Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell/experiments/sandbox/testing/nyc_squad_pretraining_validation_testing_commands.txt\n",
      "2025-11-19 07:23:51,729 - dataset_processing - INFO - Number of commands: 5\n",
      "2025-11-19 07:23:51,730 - training - INFO - copied: /Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell/experiments/sandbox/testing/nyc_squad_pretraining_validation_testing_commands.txt to: /Users/chris/PycharmProjects/Training-and-evaluating-cognitive-language-models/docker/shared_data/testing/nyc_squad_pretraining_validation_testing_commands.txt\n",
      "2025-11-19 07:23:51,736 - training - INFO - copied: /Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell/experiments/sandbox/pre_training/nyc_squad_pretraining_commands.dat to: /Users/chris/PycharmProjects/Training-and-evaluating-cognitive-language-models/docker/shared_data/pre_training/nyc_squad_pretraining_commands.dat\n",
      "2025-11-19 07:23:51,738 - dataset_processing - INFO - file written: /Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell/experiments/sandbox/testing/nyc_squad_pretraining_validation_testing_commands.txt\n",
      "2025-11-19 07:23:51,738 - dataset_processing - INFO - Number of commands: 5\n",
      "2025-11-19 07:23:51,739 - training - INFO - copied: /Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell/experiments/sandbox/testing/nyc_squad_pretraining_validation_testing_commands.txt to: /Users/chris/PycharmProjects/Training-and-evaluating-cognitive-language-models/docker/shared_data/testing/nyc_squad_pretraining_validation_testing_commands.txt\n",
      "2025-11-19 07:23:51,747 - training - INFO - copied: /Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell/experiments/sandbox/pre_training/nyc_squad_pretraining_commands.dat to: /Users/chris/PycharmProjects/Training-and-evaluating-cognitive-language-models/docker/shared_data/pre_training/nyc_squad_pretraining_commands.dat\n",
      "2025-11-19 07:23:51,748 - training - INFO - Running Docker command from directory: /Users/chris/PycharmProjects/Training-and-evaluating-cognitive-language-models/docker\n",
      "2025-11-19 07:23:51,748 - training - INFO - Command: /usr/local/bin/docker compose run --rm --entrypoint ./test_annabell_squad.sh app data/testing/annabell_pre_training_validation_testing_log.txt data/pre_training/nyc_squad_pretraining_commands.dat data/testing/nyc_squad_pretraining_validation_testing_commands.txt\n",
      "2025-11-19 07:23:54,816 - training - INFO - STDOUT: Threads max number: 12\n",
      "Free parameters:\n",
      "seed: 12345\n",
      "CW_W: 1\n",
      "InPhB_W: 3\n",
      "WkPhB_W: 1\n",
      "WkEqWG_W: 3\n",
      "WkEqGoalWG_W: 5\n",
      "GoalPhEqGoalWG_W: 1\n",
      "OutPhB_W: 1\n",
      "MaxDynamicBias_W: 500\n",
      "Enter command: .logfile data/testing/annabell_pre_training_validation_testing_log.txt\n",
      "Enter command: .stat\n",
      "Learned Words: 0\n",
      "Learned Phrases: 0\n",
      "Learned associations between word groups and phrases: 0\n",
      "IW input links: 175000\n",
      "ElActfSt neurons: 0\n",
      "ElActfSt input links: 0\n",
      "ElActfSt virtual input links: 11022840000\n",
      "ElActfSt output links: 2400000\n",
      "RemPh output links: 0\n",
      "RemPh virtual output links: 11000000000\n",
      "RemPhfWG neurons: 0\n",
      "RemPhfWG input links: 0\n",
      "RemPhfWG virtual input links: 1001000000\n",
      "RemPhfWG output links: 0\n",
      "RemPhfWG virtual output links: 10000000000\n",
      "Enter command: .load data/pre_training/nyc_squad_pretraining_commands.dat\n",
      "Enter command: #id: 5733be284776f4190066117e\n",
      "? what sit on top of the_Main_Building at Notre_Dame\n",
      ".x\n",
      " -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ...  -> Notre_Dame\n",
      " ... \n",
      "#END OF TESTING SAMPLE\n",
      "\n",
      " >>> End context\n",
      "Enter command: .stat\n",
      "Learned Words: 14\n",
      "Learned Phrases: 16\n",
      "Learned associations between word groups and phrases: 76\n",
      "IW input links: 175000\n",
      "ElActfSt neurons: 305\n",
      "ElActfSt input links: 136335\n",
      "ElActfSt virtual input links: 11022840000\n",
      "ElActfSt output links: 2400000\n",
      "RemPh output links: 114\n",
      "RemPh virtual output links: 11000000000\n",
      "RemPhfWG neurons: 76\n",
      "RemPhfWG input links: 760\n",
      "RemPhfWG virtual input links: 1001000000\n",
      "RemPhfWG output links: 76\n",
      "RemPhfWG virtual output links: 10000000000\n",
      "Enter command: .t\n",
      "Elapsed time: 2.038720\n",
      "StActMem->act_time: 0.000484\n",
      "StActMem->as_time: 0.279434\n",
      "ElActfSt->act_time: 0.106745\n",
      "ElActfSt->as_time: 0.005769\n",
      "RemPh->act_time: 0.594412\n",
      "RemPh->as_time: 0.090913\n",
      "RemPhfWG->act_time: 0.000564\n",
      "RemPhfWG->as_time: 0.109971\n",
      "ElActfSt neurons: 305\n",
      "ElActfSt links: 0\n",
      "Enter command: .logfile off\n",
      "Enter command: \n",
      "2025-11-19 07:23:54,818 - training - INFO - STDERR: time=\"2025-11-19T07:23:51Z\" level=warning msg=\"Found orphan containers ([annabell-app-run-f3739c300708 annabell-app-run-5128406719d6 annabell-app-run-cb07c11cd981]) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up.\"\n",
      "\n",
      "2025-11-19 07:23:54,818 - training - INFO - \n",
      "Docker command executed successfully.\n",
      "2025-11-19 07:23:54,819 - training - INFO - moved: /Users/chris/PycharmProjects/Training-and-evaluating-cognitive-language-models/docker/shared_data/testing/annabell_pre_training_validation_testing_log.txt to: /Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell/experiments/sandbox/logs/annabell_pre_training_validation_testing_log.txt\n",
      "2025-11-19 07:23:54,819 - pipeline - INFO - Pre-training testing completed.\n",
      "2025-11-19 07:23:54,820 - pipeline - INFO - Starting evaluation of pre-training results...\n",
      "2025-11-19 07:23:54,821 - testing - INFO - length of log file questions and answers: 1\n",
      "2025-11-19 07:23:54,823 - testing - INFO - number of test samples not found in training data: 0\n",
      "2025-11-19 07:23:54,823 - testing - INFO - test samples not found in training data: [] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test answer embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-19 07:23:55,983 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test answer embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Generating response answer embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-19 07:23:56,097 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating response answer embeddings: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-19 07:23:56,104 - testing - INFO - number of test answers longer than 20 words: 0\n",
      "2025-11-19 07:23:56,104 - testing - INFO - number correct = 0 out of 1\n",
      "2025-11-19 07:23:56,105 - testing - INFO - percentage correct = 0.0 %\n",
      "2025-11-19 07:23:56,108 - testing - INFO - number any word matches = 0 out of 1\n",
      "2025-11-19 07:23:56,109 - testing - INFO - percentage any word matches = 0.0 %\n",
      "2025-11-19 07:23:56,109 - testing - INFO - number of rows with cosine distance less than 0.1: 0\n",
      "2025-11-19 07:23:56,110 - testing - INFO - percentage of total: <bound method AnnabellTestResultsEvaluator.percentage_of_answers_below_cosine_distance_threshold of <testing.AnnabellTestResultsEvaluator object at 0x15d718260>> %\n",
      "2025-11-19 07:23:56,110 - testing - INFO - number of rows with cosine distance less than 0.1 and any matching answer correct: 0\n",
      "percentage of total: 0.0 %\n",
      "2025-11-19 07:23:56,114 - testing - INFO - total number of test samples in input file: 1\n",
      "results written to /Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell/experiments/sandbox/pre_training/results/test_detailed_results_tsv and /Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell/experiments/sandbox/pre_training/results/test_summary_results_txt\n",
      "2025-11-19 07:23:56,123 - pipeline - INFO - Evaluation of pre-training results completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from training import AnnabellPreTrainingTestingRunner\n",
    "\n",
    "pipeline = Pipeline(prepared_dataset_filepath=global_config.prepared_dataset_with_commands_filepath())\n",
    "pipeline.load_prepared_dataset()\n",
    "runner = AnnabellPreTrainingTestingRunner(pipeline.dataset_processor)"
   ],
   "id": "5204822f7739bd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from spacy.cli import download\n",
    "\n",
    "\n",
    "def _load_spacy_model(model_name):\n",
    "    \"\"\"Loads a spaCy model, downloading it if necessary.\"\"\"\n",
    "    try:\n",
    "        return spacy.load(model_name)\n",
    "    except OSError:\n",
    "        download(model_name)\n",
    "        return spacy.load(model_name)\n",
    "\n",
    "\n",
    "# Load the small English model\n",
    "nlp = _load_spacy_model(\"en_core_web_sm\")"
   ],
   "id": "2e83d1be16a1feec",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m785.8 kB/s\u001B[0m  \u001B[33m0:00:16\u001B[0m0:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001B[38;5;3m⚠ Restart to reload dependencies\u001B[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "--- Token and Dependency Analysis ---\n",
      "TOKEN      LEMMA      DEP        HEAD      \n",
      "----------------------------------------\n",
      "what       what       nsubj      sit       \n",
      "sit        sit        ROOT       sit       \n",
      "on         on         prep       sit       \n",
      "top        top        pobj       on        \n",
      "of         of         prep       top       \n",
      "the        the        det        Main_Building\n",
      "Main_Building main_building pobj       of        \n",
      "at         at         prep       sit       \n",
      "Notre_Dame Notre_Dame pobj       at        \n"
     ]
    }
   ],
   "execution_count": 3,
   "source": [
    "\n",
    "# The sentence (adjusting for the standard space usage)\n",
    "text = \"what sit on top of the Main_Building at Notre_Dame\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "print(\"--- Token and Dependency Analysis ---\")\n",
    "print(\"{:<10} {:<10} {:<10} {:<10}\".format(\"TOKEN\", \"LEMMA\", \"DEP\", \"HEAD\"))\n",
    "print(\"-\" * 40)\n",
    "for token in doc:\n",
    "    # DEP: The dependency relation label\n",
    "    # HEAD: The head token of this token\n",
    "    print(\"{:<10} {:<10} {:<10} {:<10}\".format(\n",
    "        token.text, token.lemma_, token.dep_, token.head.text\n",
    "    ))\n",
    "\n"
   ],
   "id": "20622e04cc4014aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T08:56:16.802755Z",
     "start_time": "2025-11-19T08:56:16.676974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.serve(doc, style=\"dep\")"
   ],
   "id": "7397b91816aba606",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E1050] Port 5000 is already in use. Please specify an available port with `displacy.serve(doc, port=port)` or use `auto_select_port=True` to pick an available port automatically.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mspacy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m displacy\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mdisplacy\u001B[49m\u001B[43m.\u001B[49m\u001B[43mserve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstyle\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdep\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Training-and-evaluating-cognitive-language-models/.venv/lib/python3.12/site-packages/spacy/displacy/__init__.py:105\u001B[39m, in \u001B[36mserve\u001B[39m\u001B[34m(docs, style, page, minify, options, manual, port, host, auto_select_port)\u001B[39m\n\u001B[32m     88\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Serve displaCy visualisation.\u001B[39;00m\n\u001B[32m     89\u001B[39m \n\u001B[32m     90\u001B[39m \u001B[33;03mdocs (list or Doc): Document(s) to visualise.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    101\u001B[39m \u001B[33;03mUSAGE: https://spacy.io/usage/visualizers\u001B[39;00m\n\u001B[32m    102\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    103\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mwsgiref\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m simple_server\n\u001B[32m--> \u001B[39m\u001B[32m105\u001B[39m port = \u001B[43mfind_available_port\u001B[49m\u001B[43m(\u001B[49m\u001B[43mport\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauto_select_port\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    107\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_in_jupyter():\n\u001B[32m    108\u001B[39m     warnings.warn(Warnings.W011)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Training-and-evaluating-cognitive-language-models/.venv/lib/python3.12/site-packages/spacy/util.py:1884\u001B[39m, in \u001B[36mfind_available_port\u001B[39m\u001B[34m(start, host, auto_select)\u001B[39m\n\u001B[32m   1882\u001B[39m port = start\n\u001B[32m   1883\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m auto_select:\n\u001B[32m-> \u001B[39m\u001B[32m1884\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(Errors.E1050.format(port=port))\n\u001B[32m   1886\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m _is_port_in_use(port, host) \u001B[38;5;129;01mand\u001B[39;00m port < \u001B[32m65535\u001B[39m:\n\u001B[32m   1887\u001B[39m     port += \u001B[32m1\u001B[39m\n",
      "\u001B[31mValueError\u001B[39m: [E1050] Port 5000 is already in use. Please specify an available port with `displacy.serve(doc, port=port)` or use `auto_select_port=True` to pick an available port automatically."
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
