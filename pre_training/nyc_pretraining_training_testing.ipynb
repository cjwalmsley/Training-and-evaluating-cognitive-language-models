{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# This notebook creates the datasets for pretraining, training and testing the ANNABELL model using the NYC dataset derived from SQuAD.",
   "id": "56648ebe77800a19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T08:18:56.291427Z",
     "start_time": "2025-11-05T08:18:56.279475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "from dataset_processing import AnnabellCommandGenerator, \\\n",
    "    DatasetPreProcessor, merge_categories, select_pretraining_data, write_pretraining_file, \\\n",
    "    write_testing_file, write_training_file\n",
    "\n",
    "from config.global_config import GlobalConfig\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "\n",
    "global_config = GlobalConfig()\n",
    "percentage_of_pretraining_samples = global_config.percentage_of_pre_training_samples()\n",
    "maximum_number_of_words = global_config.maximum_number_of_words()\n",
    "maximum_word_length = global_config.maximum_word_length()\n",
    "dataset_filepath = global_config.prepared_dataset_filepath()\n",
    "categorised_questions_filepath = global_config.categorised_questions_filepath()\n",
    "categorised_sentences_filepath = global_config.categorised_statements_filepath()\n",
    "pretraining_filepath = global_config.pre_training_filepath()\n",
    "training_filepath = global_config.training_filepath()\n",
    "testing_filepath = global_config.testing_filepath()\n",
    "pretraining_validation_testing_filepath = global_config.pre_training_validation_testing_filepath()\n",
    "logs_directory = global_config.log_archive_directory()"
   ],
   "id": "c7faeceb19a1aa0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "datasetPreProcessor = DatasetPreProcessor(global_config.prepared_dataset_filepath(),\n",
    "                                          global_config.maximum_number_of_words(), global_config.maximum_word_length())\n",
    "datasetPreProcessor.preprocess_data()\n",
    "nyc_squad_df = datasetPreProcessor.dataset\n",
    "nyc_squad_df = merge_categories(nyc_squad_df, global_config.categorised_questions_filepath(),\n",
    "                                global_config.categorised_statements_filepath())\n",
    "nyc_dataframe = select_pretraining_data(nyc_squad_df, global_config.percentage_of_pre_training_samples())\n",
    "nyc_dataframe"
   ],
   "id": "ada2293b524565c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### create the pretraining data\n",
    "Select the rows where the pretraining is true, generate a set of commands for each row and save to a file."
   ],
   "id": "1a14d58f1bfc43ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T08:19:06.260820Z",
     "start_time": "2025-11-05T08:19:06.015983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#add a new column to the dataframe with the created list of commands\n",
    "nyc_squad_df[\"created_commands\"] = nyc_squad_df.apply(\n",
    "    lambda row: AnnabellCommandGenerator(\n",
    "        row['id'], row['response_declarative_sentence_formatted'], row['response_question_formatted'],\n",
    "        row['response_answer_formatted']\n",
    "    ).create_list_of_commands(),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "nyc_squad_training_df = nyc_squad_df[nyc_squad_df[\"is_pretraining\"] == False]\n",
    "nyc_squad_pretraining_df = nyc_squad_df[nyc_squad_df[\"is_pretraining\"] == True]\n",
    "#save the final dataframe as a JSON lines file\n",
    "nyc_squad_df.to_json(global_config.prepared_dataset_with_commands_filepath(), orient=\"records\",\n",
    "                     lines=True)"
   ],
   "id": "11c6634dc7bd8a5c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Write the files containing the commands to perform pretraining, training and testing on ANNABELL",
   "id": "8a57ccbb2a8bae17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T08:19:10.937829Z",
     "start_time": "2025-11-05T08:19:10.915927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "write_pretraining_file(global_config.pre_training_filepath(), nyc_squad_pretraining_df)\n",
    "write_training_file(global_config.training_filepath(), nyc_squad_training_df)\n",
    "write_testing_file(global_config.testing_filepath(), nyc_squad_training_df)\n",
    "write_testing_file(global_config.pre_training_validation_testing_filepath(), nyc_squad_pretraining_df)"
   ],
   "id": "6df6815b3ac3b8f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-05 08:19:10,925 - dataset_processing - INFO - Wrote /Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell/experiments/15/pre_training/nyc_squad_pretraining_commands.txt\n",
      "2025-11-05 08:19:10,927 - dataset_processing - INFO - Number of reward lines: 42\n",
      "2025-11-05 08:19:10,927 - dataset_processing - INFO - Number of commands: 773\n",
      "2025-11-05 08:19:10,930 - dataset_processing - INFO - file written: /Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell/experiments/15/training/nyc_squad_training_commands.txt\n",
      "2025-11-05 08:19:10,931 - dataset_processing - INFO - Number of commands: 2130\n",
      "2025-11-05 08:19:10,933 - dataset_processing - INFO - file written: /Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell/experiments/15/testing/nyc_squad_testing_commands.txt\n",
      "2025-11-05 08:19:10,934 - dataset_processing - INFO - Number of commands: 3550\n",
      "2025-11-05 08:19:10,935 - dataset_processing - INFO - file written: /Users/chris/Library/CloudStorage/GoogleDrive-cjameswalmsley@gmail.com/My Drive/Shared with Julia/Education/Kent University/PhD/work/annabell/experiments/15/testing/nyc_squad_pretraining_validation_testing_commands.txt\n",
      "2025-11-05 08:19:10,936 - dataset_processing - INFO - Number of commands: 210\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate the command line instructions for running the experiments",
   "id": "facd6d44c0854feb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T08:20:48.384665Z",
     "start_time": "2025-11-05T08:20:48.368303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Copy the data files to the docker shared data directory for processing\n",
    "shutil.copy(global_config.pre_training_filepath(), global_config.docker_pre_training_directory())\n",
    "shutil.copy(global_config.training_filepath(), global_config.docker_training_directory())\n",
    "shutil.copy(global_config.testing_filepath(), global_config.docker_testing_directory())\n",
    "shutil.copy(global_config.pre_training_validation_testing_filepath(), global_config.docker_testing_directory())\n",
    "\n",
    "print(\"Files copied to docker shared data directory.\")"
   ],
   "id": "14cf0fa63c4ec29e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files copied to docker shared data directory.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T08:21:07.456117Z",
     "start_time": "2025-11-05T08:21:07.452779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Create the pre-training command\n",
    "print(\n",
    "    f'docker compose run --remove-orphans --entrypoint ./pre_train_annabell_squad_nyc.sh app data/pre-training/logfile_nyc_squad_pretraining_commands.txt data/pre-training/{global_config.pre_training_filename()} data/pre-training/{global_config.pre_training_filename().replace(\".txt\", \".dat\")}')"
   ],
   "id": "8738f179683f7436",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker compose run --remove-orphans --entrypoint ./pre_train_annabell_squad_nyc.sh app data/pre-training/logfile_nyc_squad_pretraining_commands.txt data/pre-training/nyc_squad_pretraining_commands.txt data/pre-training/nyc_squad_pretraining_commands.dat\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#copy the pre-trained weights to the pre-training directory\n",
    "weights_filename = global_config.pre_training_filename().replace(\".txt\", \".dat\")\n",
    "source_path = os.path.join(global_config.get_docker_data_directory(), \"pre-training\", weights_filename)\n",
    "destination_path = os.path.join(global_config.get_docker_data_directory(), weights_filename)\n",
    "\n",
    "try:\n",
    "    shutil.copy(source_path, destination_path)\n",
    "    print(\"copied: \" + source_path + \" to: \" + destination_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Source file not found at {source_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "#move the pre-training logfile to the pre-training directory\n",
    "source_pattern = os.path.join(global_config.docker_pre_training_directory(),\n",
    "                              \"logfile_nyc_squad_pretraining_commands*\")\n",
    "destination_dir = logs_directory\n",
    "\n",
    "log_files = glob.glob(source_pattern)\n",
    "if not log_files:\n",
    "    print(f\"No log files found matching pattern: {source_pattern}\")\n",
    "\n",
    "for file_path in log_files:\n",
    "    try:\n",
    "        shutil.move(file_path, destination_dir)\n",
    "        print(f\"moved: {file_path} to: {destination_dir}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Log file not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while moving {file_path}: {e}\")"
   ],
   "id": "f01572d6c1f743e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#run the pretraining validation testing\n",
    "print(\n",
    "    f'docker compose run --remove-orphans --entrypoint ./test_annabell_squad.sh app data/testing/logfile_nyc_squad_pretraining_validation_testing_commands.txt data/pre-training/{global_config.pre_training_filename().replace(\".txt\", \".dat\")} data/testing/{global_config.pre_training_validation_testing_filename()}')"
   ],
   "id": "4975f4c1796ac913"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Copy the testing logs back to the experiment directory\n",
    "source_pattern = os.path.join(global_config.docker_testing_directory(),\n",
    "                              \"logfile_nyc_squad_pretraining_validation_testing_commands*\")\n",
    "destination_dir = global_config.log_archive_directory()\n",
    "# Find all files matching the pattern\n",
    "log_files = glob.glob(source_pattern)\n",
    "# Copy each found file to the destination directory\n",
    "for file_path in log_files:\n",
    "    try:\n",
    "        shutil.copy(file_path, destination_dir)\n",
    "        print(f\"copied: {file_path} to: {destination_dir}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Source file not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ],
   "id": "3807997cf4273bbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### perform the testing using the \"test annabell\" notebook",
   "id": "954ccacd319f5b7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T05:45:45.781667Z",
     "start_time": "2025-10-23T05:45:45.778990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#print the command to run the training\n",
    "print(\n",
    "    f'docker compose run --remove-orphans --entrypoint ./train_annabell_squad.sh app data/training/logfile_nyc_squad_training_commands.txt data/pre-training/{global_config.pre_training_filename().replace(\".txt\", \".dat\")} data/training/{global_config.training_filename().replace(\".txt\", \".dat\")} data/training/{global_config.training_filename()}')"
   ],
   "id": "6db702604cc58727",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker compose run --remove-orphans --entrypoint ./train_annabell_squad.sh app data/training/logfile_nyc_squad_training_commands.txt data/pre-training/nyc_squad_pretraining_commands_20251022_085512.dat data/training/nyc_squad_training_commands_20251022_085512.dat data/training/nyc_squad_training_commands_20251022_085512.txt\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#copy the training weights back to the experiment directory\n",
    "source_path = os.path.join(global_config.docker_training_directory(),\n",
    "                           global_config.training_filename().replace(\".txt\", \".dat\"))\n",
    "destination_path = os.path.join(global_config.training_directory(),\n",
    "                                global_config.training_filename().replace(\".txt\", \".dat\"))\n",
    "try:\n",
    "    shutil.copy(source_path, destination_path)\n",
    "    print(\"copied: \" + source_path + \" to: \" + destination_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Source file not found at {source_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "#copy the training logfile to the logs directory\n",
    "source_pattern = os.path.join(global_config.docker_training_directory(),\n",
    "                              \"logfile_nyc_squad_training_commands*\")\n",
    "destination_dir = global_config.log_archive_directory()\n",
    "# Find all files matching the pattern\n",
    "log_files = glob.glob(source_pattern)\n",
    "# Move each found file to the destination directory\n",
    "for file_path in log_files:\n",
    "    try:\n",
    "        shutil.move(file_path, destination_dir)\n",
    "        print(f\"moved: {file_path} to: {destination_dir}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Log file not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while moving {file_path}: {e}\")"
   ],
   "id": "f717b4598dbf2bdf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#print the command to run the testing\n",
    "print(\"#run the testing\")\n",
    "print(\n",
    "    f'docker compose run --remove-orphans --entrypoint ./test_annabell_squad.sh app data/testing/logfile_nyc_squad_testing_commands.txt data/training/{global_config.training_filename().replace(\".txt\", \".dat\")} data/testing/{global_config.testing_filename()}')"
   ],
   "id": "6924adba3c90e469"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Copy the testing logs back to the experiment directory\n",
    "source_pattern = os.path.join(global_config.docker_testing_directory(),\n",
    "                              \"logfile_nyc_squad_testing_commands*\")\n",
    "destination_dir = global_config.log_archive_directory()\n",
    "# Find all files matching the pattern\n",
    "log_files = glob.glob(source_pattern)\n",
    "# Copy each found file to the destination directory\n",
    "for file_path in log_files:\n",
    "    try:\n",
    "        shutil.copy(file_path, destination_dir)\n",
    "        print(f\"copied: {file_path} to: {destination_dir}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Source file not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ],
   "id": "4a35cd5915136ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Run the testing notebook to evaluate the results",
   "id": "d70e820990ad023b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
